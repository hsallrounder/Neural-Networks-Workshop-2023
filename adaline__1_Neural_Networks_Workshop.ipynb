{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsallrounder/Neural-Networks-Workshop-2023/blob/main/adaline__1_Neural_Networks_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l7ZTgfCXLsgS"
      },
      "outputs": [],
      "source": [
        "class CustomAdaline(object):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, n_iterations=100, random_state=1, learning_rate=0.01):\n",
        "\n",
        "        self.n_iterations = n_iterations\n",
        "\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "\n",
        "    '''\n",
        "\n",
        "    Batch Gradient Descent \n",
        "\n",
        "    \n",
        "\n",
        "    1. Weights are updated considering all training examples.\n",
        "\n",
        "    2. Learning of weights can continue for multiple iterations\n",
        "\n",
        "    3. Learning rate needs to be defined\n",
        "\n",
        "    '''\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "\n",
        "        self.coef_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "\n",
        "        for _ in range(self.n_iterations):\n",
        "\n",
        "              activation_function_output = self.activation_function(self.net_input(X))\n",
        "\n",
        "              errors = y - activation_function_output\n",
        "\n",
        "              self.coef_[1:] = self.coef_[1:] + self.learning_rate*X.T.dot(errors)\n",
        "\n",
        "              self.coef_[0] = self.coef_[0] + self.learning_rate*errors.sum() \n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Net Input is sum of weighted input signals\n",
        "\n",
        "    '''\n",
        "\n",
        "    def net_input(self, X):\n",
        "\n",
        "            weighted_sum = np.dot(X, self.coef_[1:]) + self.coef_[0]\n",
        "\n",
        "            return weighted_sum\n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Activation function is fed the net input. As the activation function is\n",
        "\n",
        "    an identity function, the output from activation function is same as the\n",
        "\n",
        "    input to the function.\n",
        "\n",
        "    '''\n",
        "\n",
        "    def activation_function(self, X):\n",
        "\n",
        "            return X\n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Prediction is made on the basis of output of activation function\n",
        "\n",
        "    '''\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        return np.where(self.activation_function(self.net_input(X)) >= 0.0, 1, 0) \n",
        "\n",
        "    \n",
        "\n",
        "    '''\n",
        "\n",
        "    Model score is calculated based on comparison of \n",
        "\n",
        "    expected value and predicted value\n",
        "\n",
        "    '''\n",
        "\n",
        "    def score(self, X, y):\n",
        "\n",
        "        misclassified_data_count = 0\n",
        "\n",
        "        for xi, target in zip(X, y):\n",
        "\n",
        "            output = self.predict(xi)\n",
        "\n",
        "            if(target != output):\n",
        "\n",
        "                misclassified_data_count += 1\n",
        "\n",
        "        total_data_count = len(X)\n",
        "\n",
        "        self.score_ = (total_data_count - misclassified_data_count)/total_data_count\n",
        "\n",
        "        return self.score_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.datasets import load_breast_cancer\n",
        " from sklearn.model_selection import train_test_split\n",
        " import sklearn\n",
        " import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "bc = sklearn.datasets.load_breast_cancer()\n",
        "\n",
        "X = bc.data\n",
        "\n",
        "y = bc.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate CustomPerceptron\n",
        "\n",
        "#\n",
        "\n",
        "adaline = CustomAdaline(n_iterations = 10)\n",
        "\n",
        "#\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "#\n",
        "\n",
        "adaline.fit(X_train, y_train)\n",
        "\n",
        "#\n",
        "\n",
        "# Score the model\n",
        "\n",
        "#\n",
        "\n",
        "adaline.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdCgXghDL1_2",
        "outputId": "0bec6db1-e62d-45e5-da96-5b8b507be13c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6257309941520468"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "\n",
        "#Adaline neural network\n",
        "def Adaline(Input, Target, lr=0.2, stop=0.001):\n",
        "\tweight = np.random.random(Input.shape[1])\n",
        "\tbias = np.random.random(1)\n",
        "\t\n",
        "\tError=[stop +1]\n",
        "\t# check the stop condition for the network\n",
        "\twhile Error[-1] > stop or Error[-1]-Error[-2] > 0.0001:\n",
        "\t\terror = []\n",
        "\t\tfor i in range(Input.shape[0]):\n",
        "\t\t\tY_input = sum(weight*Input[i]) + bias\n",
        "\t\t\t\n",
        "\t\t\t# Update the weight\n",
        "\t\t\tfor j in range(Input.shape[1]):\n",
        "\t\t\t\tweight[j]=weight[j] + lr*(Target[i]-Y_input)*Input[i][j]\n",
        "\n",
        "\t\t\t# Update the bias\n",
        "\t\t\tbias=bias + lr*(Target[i]-Y_input)\n",
        "\t\t\t\n",
        "\t\t\t# Store squared error value\n",
        "\t\t\terror.append((Target[i]-Y_input)**2)\n",
        "\t\t# Store sum of square errors\n",
        "\t\tError.append(sum(error))\n",
        "\t\tprint('Error :',Error[-1])\n",
        "\treturn weight, bias\n",
        "\n",
        "# Input dataset\n",
        "x = np.array([[1.0, 1.0, 1.0],\n",
        "\t\t\t[1.0, -1.0, 1.0],\n",
        "\t\t\t[-1.0, 1.0, 1.0],\n",
        "\t\t\t[-1.0, -1.0, -1.0]])\n",
        "# Target values\n",
        "t = np.array([1, 1, 1, -1])\n",
        "\n",
        "w,b = Adaline(x, t, lr=0.2, stop=0.001)\n",
        "print('weight :',w)\n",
        "print('Bias :',b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPnwffcTNAjX",
        "outputId": "09d49ae3-34f9-4cea-e51e-70e1ce58bd7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error : [2.5025736]\n",
            "Error : [0.45962094]\n",
            "Error : [0.29034608]\n",
            "Error : [0.1998885]\n",
            "Error : [0.13829832]\n",
            "Error : [0.09571295]\n",
            "Error : [0.06624173]\n",
            "Error : [0.04584511]\n",
            "Error : [0.03172886]\n",
            "Error : [0.02195917]\n",
            "Error : [0.01519768]\n",
            "Error : [0.01051813]\n",
            "Error : [0.00727948]\n",
            "Error : [0.00503804]\n",
            "Error : [0.00348677]\n",
            "Error : [0.00241315]\n",
            "Error : [0.00167011]\n",
            "Error : [0.00115587]\n",
            "Error : [0.00079996]\n",
            "weight : [0.00979267 0.00979267 0.98800648]\n",
            "Bias : [0.00979267]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict from the evaluated weight and bias of adaline\n",
        "def prediction(X,w,b):\n",
        "\ty=[]\n",
        "\tfor i in range(X.shape[0]):\n",
        "\t\tx = X[i]\n",
        "\t\ty.append(sum(w*x)+b)\n",
        "\treturn y\n",
        "prediction(x,w,b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xac2fbD4OQiF",
        "outputId": "d33d9b90-3c16-48cf-e99b-bdb95f119d0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.01738449]),\n",
              " array([0.99779915]),\n",
              " array([0.99779915]),\n",
              " array([-0.99779915])]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaline neural network\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def activation_fn(z):\n",
        "\tif z>=0:\n",
        "\t\treturn 1\n",
        "\telse:\n",
        "\t\treturn -1\n",
        "\n",
        "def Madaline(Input, Target, lr, epoch):\n",
        "\tweight = np.random.random((Input.shape[1],Input.shape[1]))\n",
        "\tbias = np.random.random(Input.shape[1])\n",
        "\t\n",
        "\tw = np.array([0.5 for i in range(weight.shape[1])])\n",
        "\tb = 0.5\n",
        "\tk = 0\n",
        "\twhile k<epoch:\n",
        "\t\terror = []\n",
        "\t\tz_input = np.zeros(bias.shape[0])\n",
        "\t\tz = np.zeros(bias.shape[0])\n",
        "\t\tfor i in range(Input.shape[0]):\n",
        "\t\t\tfor j in range(Input.shape[1]):\n",
        "\t\t\t\tz_input[j] = sum(weight[j]*Input[i]) + bias[j]\n",
        "\t\t\t\tz[j]= activation_fn(z_input[j])\n",
        "\n",
        "\t\t\ty_input = sum(z*w) +b\n",
        "\n",
        "\t\t\ty = activation_fn(y_input)\n",
        "\t\t\t# Update the weight & bias\n",
        "\t\t\tif y != Target[i]:\n",
        "\t\t\t\tfor j in range(weight.shape[1]):\n",
        "\t\t\t\t\tweight[j]= weight[j] + lr*(Target[i]-z_input[j])*Input[i][j]\n",
        "\t\t\t\t\tbias[j] = bias[j] + lr*(Target[i]-z_input[j])\n",
        "\n",
        "\t\t\t# Store squared error value\n",
        "\t\t\terror.append((Target[i]-z_input)**2)\n",
        "\t\t# compute sum of square error\n",
        "\t\tError = sum(error)\n",
        "\t\tprint(k,'>> Error :',Error)\n",
        "\t\tk+=1\n",
        "\t\t\n",
        "\treturn weight, bias\n",
        "\n",
        "# Input dataset\n",
        "x = np.array([[1.0, 1.0, 1.0], [1.0, -1.0, 1.0],\n",
        "\t\t\t[-1.0, 1.0, 1.0], [-1.0, -1.0, -1.0]])\n",
        "# Target values\n",
        "t = np.array([1, 1, 1, -1])\n",
        "\n",
        "w,b = Madaline(x, t, 0.0001, 3)\n",
        "print('weight :',w)\n",
        "print('Bias :',b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG-HJ9ODOeBT",
        "outputId": "d505aef3-1a51-49fc-b589-64dcfe54573c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 >> Error : [2.56295735 2.5206951  1.19337942]\n",
            "1 >> Error : [2.56295735 2.5206951  1.19337942]\n",
            "2 >> Error : [2.56295735 2.5206951  1.19337942]\n",
            "weight : [[0.26814528 0.36718734 0.64583917]\n",
            " [0.61708602 0.53856221 0.53408792]\n",
            " [0.20272112 0.18041101 0.15916272]]\n",
            "Bias : [0.92871092 0.81170839 0.29158872]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(X, w,b):\n",
        "\ty =[]\n",
        "\tfor i in range(X.shape[0]):\n",
        "\t\tx = X[i]\n",
        "\t\tz1 = x*w\n",
        "\t\tz_1 =[]\n",
        "\t\tfor j in range(z1.shape[1]):\n",
        "\t\t\tz_1.append(activation_fn(sum(z1[j])+b[j]))\n",
        "\t\ty_in = sum(np.array(z_1)*np.array([0.5 for j in range(w.shape[1])])) + 0.5\n",
        "\t\ty.append(activation_fn(y_in))\n",
        "\treturn y\n",
        "\n",
        "prediction(x, w,b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dufZkvWOQiPO",
        "outputId": "83101c18-84bb-4ab1-9cba-9d33de69aca1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, -1]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}