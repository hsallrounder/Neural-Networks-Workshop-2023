{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVZsG06ImhU32+X2BaA3DP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsallrounder/Neural-Networks-Workshop-2023/blob/main/MLE_Neural_Networks_Workshop_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr5ZfwBE-mwO",
        "outputId": "13b6ec0f-ed1b-41a3-de57-5aab7573e3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True mean: 2\n",
            "True standard deviation: 1.5\n",
            "Sample mean: 1.8279432273517824\n",
            "Sample standard deviation: 1.2029984782491447\n",
            "Maximum likelihood estimate for mu: 1.827943206611511\n",
            "Maximum likelihood estimate for sigma: 12.029978851434645\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate some sample data from a normal distribution\n",
        "mu_true = 2\n",
        "sigma_true = 1.5\n",
        "sample_size = 100\n",
        "data = np.random.normal(mu_true, sigma_true, sample_size)\n",
        "\n",
        "# Define the likelihood function for a normal distribution\n",
        "def normal_likelihood(mu, sigma, data):\n",
        "    log_likelihood = -0.5*np.log(2*np.pi*sigma**2) - 0.5*np.sum((data-mu)**2/sigma**2)\n",
        "    return log_likelihood\n",
        "\n",
        "# Define the negative log-likelihood function\n",
        "def neg_log_likelihood(theta, data):\n",
        "    mu, sigma = theta\n",
        "    return -normal_likelihood(mu, sigma, data)\n",
        "\n",
        "# Use SciPy's optimize function to find the maximum likelihood estimates\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Set initial values for mu and sigma\n",
        "mu0 = np.mean(data)\n",
        "sigma0 = np.std(data)\n",
        "\n",
        "# Set bounds for the optimization\n",
        "bounds = ((None, None), (0, None))\n",
        "\n",
        "# Run the optimization\n",
        "result = minimize(neg_log_likelihood, x0=[mu0, sigma0], args=(data,), bounds=bounds)\n",
        "\n",
        "# Extract the maximum likelihood estimates for mu and sigma\n",
        "mu_hat, sigma_hat = result.x\n",
        "\n",
        "print(\"True mean:\", mu_true)\n",
        "print(\"True standard deviation:\", sigma_true)\n",
        "print(\"Sample mean:\", np.mean(data))\n",
        "print(\"Sample standard deviation:\", np.std(data))\n",
        "print(\"Maximum likelihood estimate for mu:\", mu_hat)\n",
        "print(\"Maximum likelihood estimate for sigma:\", sigma_hat)"
      ]
    }
  ]
}